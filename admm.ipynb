{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "532ba2f8",
   "metadata": {},
   "source": [
    "# 交替方向乘子法（ADMM）笔记\n",
    "\n",
    "## 1. 对偶问题\n",
    "\n",
    "### 1.1 原始问题与拉格朗日函数\n",
    "考虑凸优化问题（等式约束）：\n",
    "```math\n",
    "\\begin{aligned}\n",
    "\\min_x \\quad & f(x) \\\\\n",
    "\\text{s.t.} \\quad & Ax = b\n",
    "\\end{aligned}\n",
    "```\n",
    "其中 $f(x)$ 是凸函数。\n",
    "\n",
    "**拉格朗日函数**：\n",
    "$$ L(x,y) = f(x) + y^T(Ax - b) $$\n",
    "- $y$ 是对偶变量（拉格朗日乘子）\n",
    "\n",
    "**对偶函数**：\n",
    "$$ g(y) = \\inf_x L(x,y) $$\n",
    "\n",
    "### 1.2 对偶上升法\n",
    "对偶问题：$\\max_y g(y)$\n",
    "\n",
    "**算法步骤**：\n",
    "1. $x$-更新：$x^{k+1} = \\argmin_x L(x,y^k)$\n",
    "2. 对偶更新：$y^{k+1} = y^k + \\alpha^k (Ax^{k+1} - b)$\n",
    "\n",
    "### 1.3 对偶分解\n",
    "当目标函数可分时（$f(x)=\\sum_i f_i(x_i)$），拉格朗日函数可分解：\n",
    "$$ L(x,y) = \\sum_i \\left[ f_i(x_i) + y^TA_ix_i \\right] - y^Tb $$\n",
    "\n",
    "**分布式计算**：\n",
    "1. 各节点并行计算：$x_i^{k+1} = \\argmin_{x_i} L_i(x_i,y^k)$\n",
    "2. 中心节点聚合：$y^{k+1} = y^k + \\alpha^k (\\sum_i A_ix_i^{k+1} - b)$\n",
    "\n",
    "## 2. 乘子法\n",
    "\n",
    "### 2.1 增广拉格朗日\n",
    "为增强稳定性，引入二次惩罚项：\n",
    "$$ L_\\rho(x,y) = f(x) + y^T(Ax-b) + \\frac{\\rho}{2}\\|Ax-b\\|_2^2 $$\n",
    "\n",
    "**算法步骤**：\n",
    "1. $x$-更新：$x^{k+1} = \\argmin_x L_\\rho(x,y^k)$\n",
    "2. 对偶更新：$y^{k+1} = y^k + \\rho(Ax^{k+1}-b)$\n",
    "\n",
    "### 2.2 优缺点\n",
    "- 优点：收敛条件更宽松\n",
    "- 缺点：二次项破坏可分解性\n",
    "\n",
    "## 3. 交替方向乘子法（ADMM）\n",
    "\n",
    "### 3.1 基本形式\n",
    "处理可分结构的优化问题：\n",
    "```math\n",
    "\\begin{aligned}\n",
    "\\min \\quad & f(x) + g(z) \\\\\n",
    "\\text{s.t.} \\quad & Ax + Bz = c\n",
    "\\end{aligned}\n",
    "```\n",
    "\n",
    "**增广拉格朗日**：\n",
    "$$ L_\\rho(x,z,y) = f(x)+g(z)+y^T(Ax+Bz-c)+\\frac{\\rho}{2}\\|Ax+Bz-c\\|_2^2 $$\n",
    "\n",
    "### 3.2 算法步骤\n",
    "1. $x$-更新：$x^{k+1} = \\argmin_x L_\\rho(x,z^k,y^k)$\n",
    "2. $z$-更新：$z^{k+1} = \\argmin_z L_\\rho(x^{k+1},z,y^k)$\n",
    "3. 对偶更新：$y^{k+1} = y^k + \\rho(Ax^{k+1}+Bz^{k+1}-c)$\n",
    "\n",
    "### 3.3 缩放形式\n",
    "令 $u = y/\\rho$，得到缩放形式：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x^{k+1} &= \\argmin_x \\left( f(x) + \\frac{\\rho}{2}\\|Ax+Bz^k-c+u^k\\|_2^2 \\right) \\\\\n",
    "z^{k+1} &= \\argmin_z \\left( g(z) + \\frac{\\rho}{2}\\|Ax^{k+1}+Bz-c+u^k\\|_2^2 \\right) \\\\\n",
    "u^{k+1} &= u^k + (Ax^{k+1}+Bz^{k+1}-c)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### 3.4 收敛性\n",
    "**假设条件**：\n",
    "1. $f,g$ 为凸、闭、正常函数\n",
    "2. 增广拉格朗日存在鞍点\n",
    "\n",
    "**收敛结果**：\n",
    "- 残差收敛：$Ax^k+Bz^k-c \\to 0$\n",
    "- 目标值收敛：$f(x^k)+g(z^k) \\to p^*$\n",
    "\n",
    "## 4. 常见函数更新\n",
    "\n",
    "### 4.1 可分函数\n",
    "当 $f(x)=\\sum_i f_i(x_i)$ 且 $A^TA$ 块对角时：\n",
    "- $x^+$-更新可分解为并行子问题\n",
    "\n",
    "### 4.2 近端算子\n",
    "当 $A=I$ 时，$x$更新为：\n",
    "$$ \\text{prox}_{f,\\rho}(v) = \\argmin_x \\left( f(x) + \\frac{\\rho}{2}\\|x-v\\|_2^2 \\right) $$\n",
    "\n",
    "**特例**：\n",
    "1. 投影：$f=I_C \\Rightarrow \\Pi_C(v)$\n",
    "2. L1正则：$f=\\lambda\\|\\cdot\\|_1 \\Rightarrow$ 软阈值 $S_{\\lambda/\\rho}(v_i)$\n",
    "\n",
    "### 4.3 二次目标\n",
    "当 $f(x)=\\frac{1}{2}x^TPx+q^Tx+r$ 时：\n",
    "$$ x^+ = (P+\\rho A^TA)^{-1}(\\rho A^Tv - q) $$\n",
    "\n",
    "**计算技巧**：\n",
    "- 矩阵求逆引理\n",
    "- 预计算分解\n",
    "\n",
    "## 5. 典型应用：Lasso回归\n",
    "问题形式：\n",
    "$$ \\min \\frac{1}{2}\\|Ax-b\\|_2^2 + \\lambda\\|z\\|_1 \\quad \\text{s.t.} \\ x-z=0 $$\n",
    "\n",
    "相当于$f(x)$为二次目标，$f(z)$为L1正则。ADMM步骤：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x^{k+1} &= (A^TA+\\rho I)^{-1}(A^Tb + \\rho z^k - y^k) \\\\\n",
    "z^{k+1} &= S_{\\lambda/\\rho}(x^{k+1}+y^k/\\rho) \\\\\n",
    "y^{k+1} &= y^k + \\rho(x^{k+1}-z^{k+1})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "## 6. 总结\n",
    "\n",
    "**优势**：\n",
    "- 适用于大规模分布式优化\n",
    "- 对不可微函数友好\n",
    "- 收敛性有保证\n",
    "\n",
    "**挑战**：\n",
    "- 参数 $\\rho$ 需要调节\n",
    "- 非凸问题收敛性复杂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba1c1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def soft_threshold(v, thresh):\n",
    "    \"\"\"元素级软阈值.\"\"\"\n",
    "    return np.sign(v) * np.maximum(np.abs(v) - thresh, 0.0)\n",
    "\n",
    "def admm_lasso(A, b, lamb=1.0, rho=1.0, \n",
    "               max_iter=1000, abstol=1e-4, reltol=1e-3, \n",
    "               verbose=False):\n",
    "    m, n = A.shape\n",
    "    # 预计算常量\n",
    "    Atb = A.T @ b\n",
    "    # (AᵀA + ρI) 预分解（Cholesky 比较稳）\n",
    "    L = np.linalg.cholesky(A.T @ A + rho * np.eye(n))\n",
    "    U = L.T\n",
    "\n",
    "    # 初始化\n",
    "    x = np.zeros(n)\n",
    "    z = np.zeros(n)\n",
    "    u = np.zeros(n)\n",
    "\n",
    "    for k in range(max_iter):\n",
    "        # x-步：解线性系统\n",
    "        q = Atb + rho * (z - u)          # 右端向量\n",
    "        # 通过两次三角解算 (L y = q ; U x = y)\n",
    "        x = np.linalg.solve(U, np.linalg.solve(L, q))\n",
    "\n",
    "        # z-步：软阈值\n",
    "        z_old = z.copy()\n",
    "        z = soft_threshold(x + u, lamb / rho)\n",
    "\n",
    "        # u-步：对偶变量\n",
    "        u += x - z\n",
    "\n",
    "        # 收敛性检查\n",
    "        r_norm = np.linalg.norm(x - z)          # 原始残差\n",
    "        s_norm = np.linalg.norm(-rho * (z - z_old))  # 对偶残差\n",
    "\n",
    "        eps_pri = np.sqrt(n) * abstol + reltol * max(np.linalg.norm(x), np.linalg.norm(z))\n",
    "        eps_dual = np.sqrt(n) * abstol + reltol * np.linalg.norm(rho * u)\n",
    "\n",
    "        if verbose and (k % 50 == 0 or k == max_iter - 1):\n",
    "            print(f\"iter {k:4d} | r {r_norm:.3e} | s {s_norm:.3e} | eps_pri {eps_pri:.3e} | eps_dual {eps_dual:.3e}\")\n",
    "\n",
    "        if r_norm < eps_pri and s_norm < eps_dual:\n",
    "            print(f\"iter {k:4d} | r {r_norm:.3e} | s {s_norm:.3e} | eps_pri {eps_pri:.3e} | eps_dual {eps_dual:.3e}\")\n",
    "            break\n",
    "\n",
    "    return x, {'iterations': k+1, 'r_norm': r_norm, 's_norm': s_norm}\n",
    "\n",
    "# 生成一个简单的稀疏回归测试\n",
    "np.random.seed(42)\n",
    "m, n, sparsity = 200, 500, 0.1\n",
    "A = np.random.randn(m, n)\n",
    "x_true = np.zeros(n)\n",
    "support = np.random.choice(n, int(sparsity * n), replace=False)\n",
    "x_true[support] = np.random.randn(len(support))\n",
    "b = A @ x_true + 0.01 * np.random.randn(m)\n",
    "\n",
    "# 运行 ADMM-Lasso\n",
    "lamb = 0.1          # 正则超参数，可网格搜索\n",
    "rho = 1.0           # ADMM 惩罚参数，可用 residual balance 调节\n",
    "x_est, info = admm_lasso(A, b, lamb, rho, verbose=True)\n",
    "\n",
    "print(\"非零个数:\", np.count_nonzero(x_est))\n",
    "print(\"重构误差:\", np.linalg.norm(x_est - x_true))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
